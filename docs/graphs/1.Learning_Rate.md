# Learning Rate Dynamics & Loss Landscapes

## 1. The Gradient Descent Update
The core mechanic of training is the weight update. The **Learning Rate** ($\eta$) determines the magnitude of the step taken against the gradient.

$$
w_{new} = w_{old} - \eta \cdot \nabla_{w} L
$$

* $\nabla_{w} L$: The gradient (derivative) of the Loss function with respect to weight $w$.
* $\eta$: The scalar Learning Rate (hyperparameter).

---

## 2. Visualizing Learning Rate Impact

The choice of learning rate drastically changes how the optimizer traverses the loss landscape.

### A. High Learning Rate (Instability)
If $\eta$ is too high, the optimizer steps *over* the minimum and lands on a higher loss value, causing the model to oscillate or explode.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image_dbf8f3.png}
    \caption{Fig 10.09: Unstable model, learning rate too big.}
    \label{fig:high_lr}
\end{figure}

### B. Low Learning Rate (Slow Convergence)
If $\eta$ is too low, the updates are infinitesimal. The model is stable and will eventually reach the minimum, but it requires an impractical number of epochs to train.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image_dbf930.png}
    \caption{Fig 10.06: Reached the global minimum, too low learning rate.}
    \label{fig:low_lr}
\end{figure}

---

## 3. The "Local Minimum" Trap
In complex loss landscapes (non-convex functions), a static learning rate can easily get stuck in a **Local Minimum**â€”a valley that is lower than its immediate surroundings but not the lowest point in the entire landscape (Global Minimum).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image_dbf94f.png}
    \caption{Fig 10.05: Stuck in the third local minimum, near the global minimum.}
    \label{fig:local_min}
\end{figure}

---

## 4. Efficient Learning
The goal is to find a learning rate (or an adaptive strategy) that descends quickly initially but slows down enough to settle into the Global Minimum without overshooting.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image_dbf89b.png}
    \caption{Fig 10.13: An efficient learning example.}
    \label{fig:efficient_lr}
\end{figure}